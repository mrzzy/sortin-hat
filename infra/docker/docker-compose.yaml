#
# Sortin-hat
# Local Development
# Docker-compose
#

# NOTE: expects a '.env' file in the same directory that defines environment variables.
# see the template 'env' file for which variables to define.

services:
  # Airflow Deployment
  airflow-postgres:
    restart: on-failure
    image: postgres:14.5-alpine
    env_file: .env
    expose:
      - 5432
    volumes:
      - airflow-db:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "${POSTGRES_USER}"]
      interval: 5s
      retries: 5

  airflow-migrate-db:
    depends_on:
      airflow-postgres:
        condition: service_healthy
    build: ../../pipeline
    environment:
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: "postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@airflow-postgres/${POSTGRES_DB}"
    command: ["airflow", "db", "init"]

  airflow:
    depends_on:
      airflow-migrate-db:
        condition: service_completed_successfully
    restart: on-failure
    build: ../../pipeline
    ports:
      - 8080:8080
    environment:
      AIRFLOW__CORE__LOAD_EXAMPLES: False
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: "postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@airflow-postgres/${POSTGRES_DB}"
      AIRFLOW_CONN_GOOGLE_CLOUD_DEFAULT: "google-cloud-platform://?extra__google_cloud_platform__key_path=%2Fopt%2Fairflow%2Fgcp_key.json"
    volumes:
      - ../../pipeline/src:/opt/airflow/dags:r
      - "${GOOGLE_APPLICATION_CREDENTIALS}:/opt/airflow/gcp_key.json:r"
    # consolidates all services needed to run airflow in 1 container.
    command: ["airflow", "standalone"]

  # MLFlow Deployment
  mlflow-postgres:
    restart: on-failure
    image: postgres:14.5-alpine
    env_file: .env
    expose:
      - 5432
    volumes:
      - mlflow-db:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "${POSTGRES_USER}"]
      interval: 5s
      retries: 5

  mlflow:
    depends_on:
      mlflow-postgres:
        condition: service_healthy
    restart: on-failure
    build: ./mlflow
    command: [
      "mlflow", "server",
      "--default-artifact-root", "gs://sss-sortin-hat-models",
      "--backend-store-uri",  "postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@mlflow-postgres/${POSTGRES_DB}"
    ]
    ports:
      - 5000:8082

  # Single-Node Ray Cluster
  ray:
    restart: on-failure
    image: rayproject/ray:2.1.0-py38-cpu
    command: ["ray", "start", "--head", "--block", "--port=6379"]
    ports:
      - 6379:8081

volumes:
  airflow-db: {}
  mlflow-db: {}
